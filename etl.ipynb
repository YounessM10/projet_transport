{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table dim_air_no2 chargée avec succès.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table dim_entreprise chargée avec succès.\n",
      "Table dim_population chargée avec succès.\n",
      "Table dim_transport chargée avec succès.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table dim_deplacement chargée avec succès.\n",
      "Table dim_fact_table chargée avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Chemin vers le Data Lake\n",
    "data_lake_path = \"./DataLake\"\n",
    "output_path = \"./ExportedFiles\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "engine = create_engine(\"postgresql+psycopg2://xxx:xxx@localhost/transport\")\n",
    "\n",
    "# Fonction pour charger les données dans PostgreSQLr\n",
    "def load_data_to_sql(table_name, dataframe):\n",
    "    try:\n",
    "        dataframe.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "        print(f\"Table {table_name} chargée avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement de la table {table_name}: {e}\")\n",
    "\n",
    "#air NO2\n",
    "columns_keep_air_no2 = [\n",
    " \"Date de début\",\"Date de fin\", \"code site\", \"nom site\", \"valeur\", \"valeur brute\",\n",
    " \"taux de saisie\", \"couverture de données\", \"code qualité\",\"validité\",\"Latitude\",\"Longitude\",\"code postal\"\n",
    " ]\n",
    "air_no2 = pd.read_csv(os.path.join(data_lake_path, \"data_air_no2/data_air_no2.csv\"),encoding='ISO-8859-1', sep=\";\", usecols=columns_keep_air_no2)\n",
    "air_no2 = air_no2.dropna(subset=[\"code postal\",\"valeur\"])\n",
    "load_data_to_sql(\"dim_air_no2\", air_no2)\n",
    "\n",
    "#entreprise\n",
    "columns_keep_entreprise = [\n",
    "  \"Département\", \"Nom commune\", \"Commune\", \"Grand secteur d'activité\", \"APE\", \"Code région\", \"Code département\",\n",
    "  \"Nombre d'établissements 2024\", \"Effectifs salariés 2024\"\n",
    "]\n",
    "entreprise = pd.read_csv(os.path.join(data_lake_path, \"entreprise/etablissements-et-effectifs-salaries.csv\"),encoding='ISO-8859-1', sep=\";\", usecols=columns_keep_entreprise)\n",
    "entreprise.rename(columns={'Commune': 'code postal'}, inplace=True)\n",
    "entreprise = entreprise.dropna(subset=[\"code postal\",\"Effectifs salariés 2024\"])\n",
    "load_data_to_sql(\"dim_entreprise\", entreprise)\n",
    "\n",
    "#population\n",
    "columns_keep_population = [\"codgeo\", \"libgeo\", \"p24_pop\"]\n",
    "population = pd.read_csv(os.path.join(data_lake_path, \"population/population.csv\"),encoding='ISO-8859-1' , sep=\";\", usecols=columns_keep_population)\n",
    "population.rename(columns={'codgeo': 'code postal'}, inplace=True)\n",
    "population = population.dropna(subset=[\"code postal\",\"p24_pop\"])\n",
    "load_data_to_sql(\"dim_population\", population)\n",
    "\n",
    "#transport\n",
    "columns_keep_transport = [\"stop_name\", \"stop_lon\", \"stop_lat\", \"shortName\", \"mode\", \"Pointgeo\", \"Nom_commune\", \"Code_insee\"]\n",
    "transport = pd.read_csv(os.path.join(data_lake_path, \"transports/transports.csv\"),encoding='ISO-8859-1', sep=\";\", usecols=columns_keep_transport)\n",
    "transport.rename(columns={'Code_insee': 'code postal'}, inplace=True)\n",
    "transport = transport.dropna(subset=[\"code postal\",\"mode\"])\n",
    "load_data_to_sql(\"dim_transport\", transport)\n",
    "\n",
    "#deplacement domicile-travail\n",
    "columns_keep_deplacement = [\"LIEU_RESID\", \"LIEU_TRAV\", \"MODTRANS\", \"DIST\", \"DUREE\", \"CHAMP_CO2\", \"DIST_HEBDO\", \"CARBU_HEBDO\", \"CO2_HEBDO\"]\n",
    "deplacement = pd.read_csv(os.path.join(data_lake_path, \"deplacement/depl_dom_trav_co2.csv\"), sep=\";\", usecols=columns_keep_deplacement)\n",
    "deplacement = deplacement.dropna(subset=[\"LIEU_TRAV\",\"CO2_HEBDO\"])\n",
    "load_data_to_sql(\"dim_deplacement\", deplacement)\n",
    "\n",
    "\n",
    "air_no2_agg = air_no2.groupby(\"code postal\").agg(\n",
    "    no2_moyenne=(\"valeur\", \"mean\"),\n",
    "    no2_min=(\"valeur\", \"min\"),\n",
    "    no2_max=(\"valeur\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "fact_table = pd.merge(air_no2_agg, population, on=\"code postal\", how=\"left\")\n",
    "fact_table = pd.merge(fact_table, entreprise, on=\"code postal\", how=\"left\")\n",
    "\n",
    "transport_agg = transport.groupby(\"code postal\").agg(\n",
    "    nb_stops=(\"stop_name\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "fact_table = pd.merge(fact_table, transport_agg, on=\"code postal\", how=\"left\")\n",
    "\n",
    "deplacement[\"DIST\"] = deplacement[\"DIST\"].str.replace(\",\", \".\", regex=False).astype(float)\n",
    "deplacement[\"CO2_HEBDO\"] = deplacement[\"CO2_HEBDO\"].str.replace(\",\", \".\", regex=False).astype(float)\n",
    "deplacement = deplacement.dropna(subset=[\"DIST\", \"CO2_HEBDO\"])\n",
    "deplacement_agg = deplacement.groupby(\"LIEU_TRAV\").agg(\n",
    "    distance_moyenne=(\"DIST\", \"mean\"),\n",
    "    co2_hebdo_moyen=(\"CO2_HEBDO\", \"mean\")\n",
    ").reset_index()\n",
    "fact_table = pd.merge(fact_table, deplacement_agg, left_on=\"code postal\", right_on=\"LIEU_TRAV\", how=\"left\")\n",
    "\n",
    "fact_table[\"no2_par_habitant\"] = fact_table[\"no2_moyenne\"] / fact_table[\"p24_pop\"]\n",
    "fact_table[\"nbr_salarie_par_code_postal\"] = fact_table.groupby(\"code postal\")[\"Effectifs salariés 2024\"].transform(\"sum\")\n",
    "fact_table[\"no2_par_salarie\"] = fact_table[\"no2_moyenne\"] / fact_table[\"nbr_salarie_par_code_postal\"]\n",
    "fact_table[\"co2_par_km\"] = fact_table[\"co2_hebdo_moyen\"] / fact_table[\"distance_moyenne\"]\n",
    "\n",
    "fact_table.fillna(0, inplace=True)\n",
    "fact_table = fact_table[[\"code postal\", \"no2_moyenne\", \"no2_min\", \"no2_max\", \"nb_stops\", \"distance_moyenne\", \"co2_hebdo_moyen\", \"no2_par_habitant\", \"no2_par_salarie\", \"nbr_salarie_par_code_postal\", \"co2_par_km\"]]\n",
    "fact_table = fact_table.drop_duplicates(subset=[\"code postal\"], keep=\"first\")\n",
    "load_data_to_sql(\"dim_fact_table\", fact_table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Export des données\n",
    "fact_table.to_csv(os.path.join(output_path, \"fact_table.csv\"), index=False, sep=\";\")\n",
    "air_no2.to_csv(os.path.join(output_path, \"air_no2_clean.csv\"), index=False, sep=\";\")\n",
    "entreprise.to_csv(os.path.join(output_path, \"entreprise_clean.csv\"), index=False, sep=\";\")\n",
    "population.to_csv(os.path.join(output_path, \"population_clean.csv\"), index=False, sep=\";\")\n",
    "transport.to_csv(os.path.join(output_path, \"transport_clean.csv\"), index=False, sep=\";\")\n",
    "deplacement.to_csv(os.path.join(output_path, \"deplacement_clean.csv\"), index=False, sep=\";\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
